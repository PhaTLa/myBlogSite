# X√¢y d·ª±ng c√°c c·ª•m Kubernetes s·∫µn s√†ng s·∫£n xu·∫•t tr√™n AWS EKS


<p align="center">
    <img src="https://pub-012e0e3c1b2643639bffe9b7fd5624e5.r2.dev/homelab.jpg" alt="Ph·∫°m T√πng L√¢m Homelab" title="DevOps Engineer & Solution Architect" style="width:100%; height:240px; object-fit:cover; box-shadow:0 2px 8px rgba(0,0,0,0.1);" />
</p>

# X√¢y d·ª±ng c√°c c·ª•m Kubernetes s·∫µn s√†ng s·∫£n xu·∫•t tr√™n AWS EKS

Amazon Elastic Kubernetes Service (EKS) ƒë√£ tr·ªü th√†nh gi·∫£i ph√°p h√†ng ƒë·∫ßu ƒë·ªÉ ch·∫°y c√°c workload Kubernetes trong AWS. Tuy nhi√™n, vi·ªác thi·∫øt l·∫≠p m·ªôt c·ª•m EKS th·ª±c s·ª± s·∫µn s√†ng cho s·∫£n xu·∫•t ƒë√≤i h·ªèi nhi·ªÅu h∆°n vi·ªác ch·ªâ nh·∫•p "Create Cluster" trong console AWS. Trong b√†i vi·∫øt n√†y, t√¥i s·∫Ω h∆∞·ªõng d·∫´n b·∫°n qua c√°c th√†nh ph·∫ßn thi·∫øt y·∫øu v√† th·ª±c ti·ªÖn t·ªët nh·∫•t m√† t√¥i ƒë√£ h·ªçc ƒë∆∞·ª£c t·ª´ vi·ªác tri·ªÉn khai v√† qu·∫£n l√Ω c√°c c·ª•m EKS trong m√¥i tr∆∞·ªùng s·∫£n xu·∫•t.

## üéØ ƒêi·ªÅu g√¨ khi·∫øn m·ªôt c·ª•m "S·∫µn s√†ng s·∫£n xu·∫•t"?

Tr∆∞·ªõc khi ƒëi v√†o chi ti·∫øt k·ªπ thu·∫≠t, h√£y ƒë·ªãnh nghƒ©a √Ω nghƒ©a c·ªßa "s·∫µn s√†ng s·∫£n xu·∫•t":

- **T√≠nh kh·∫£ d·ª•ng cao**: Tri·ªÉn khai Multi-AZ v·ªõi ph√¢n ph·ªëi node h·ª£p l√Ω
- **B·∫£o m·∫≠t**: C√¥ l·∫≠p m·∫°ng, RBAC, ti√™u chu·∫©n b·∫£o m·∫≠t pod
- **Kh·∫£ nƒÉng quan s√°t**: Gi√°m s√°t, logging v√† c·∫£nh b√°o to√†n di·ªán
- **Kh·∫£ nƒÉng m·ªü r·ªông**: Kh·∫£ nƒÉng t·ª± ƒë·ªông m·ªü r·ªông cho c·∫£ node v√† pod
- **Kh√¥i ph·ª•c th·∫£m h·ªça**: Chi·∫øn l∆∞·ª£c sao l∆∞u v√† quy tr√¨nh kh√¥i ph·ª•c
- **T·ªëi ∆∞u h√≥a chi ph√≠**: ƒê·ªãnh k√≠ch th∆∞·ªõc ƒë√∫ng v√† s·ª≠ d·ª•ng t√†i nguy√™n hi·ªáu qu·∫£

## üèóÔ∏è N·ªÅn t·∫£ng h·∫° t·∫ßng

### Thi·∫øt k·∫ø VPC

N·ªÅn t·∫£ng c·ªßa b·∫•t k·ª≥ c·ª•m EKS n√†o l√† m·ªôt VPC ƒë∆∞·ª£c thi·∫øt k·∫ø t·ªët. ƒê√¢y l√† ki·∫øn tr√∫c m√† t√¥i th∆∞·ªùng s·ª≠ d·ª•ng:

```yaml
# terraform/vpc.tf
module "vpc" {
  source = "terraform-aws-modules/vpc/aws"
  
  name = "eks-production-vpc"
  cidr = "10.0.0.0/16"
  
  azs             = ["us-west-2a", "us-west-2b", "us-west-2c"]
  private_subnets = ["10.0.1.0/24", "10.0.2.0/24", "10.0.3.0/24"]
  public_subnets  = ["10.0.101.0/24", "10.0.102.0/24", "10.0.103.0/24"]
  
  enable_nat_gateway = true
  enable_vpn_gateway = false
  enable_dns_hostnames = true
  enable_dns_support = true
  
  # B·∫Øt bu·ªôc cho EKS
  public_subnet_tags = {
    "kubernetes.io/cluster/${var.cluster_name}" = "shared"
    "kubernetes.io/role/elb"                    = "1"
  }
  
  private_subnet_tags = {
    "kubernetes.io/cluster/${var.cluster_name}" = "shared"
    "kubernetes.io/role/internal-elb"           = "1"
  }
}
```

### C·∫•u h√¨nh c·ª•m EKS

```yaml
# terraform/eks.tf
module "eks" {
  source = "terraform-aws-modules/eks/aws"
  
  cluster_name    = var.cluster_name
  cluster_version = "1.28"
  
  vpc_id     = module.vpc.vpc_id
  subnet_ids = module.vpc.private_subnets
  
  # C·∫•u h√¨nh endpoint c·ª•m
  cluster_endpoint_private_access = true
  cluster_endpoint_public_access  = true
  cluster_endpoint_public_access_cidrs = ["0.0.0.0/0"]
  
  # M√£ h√≥a c·ª•m
  cluster_encryption_config = [{
    provider_key_arn = aws_kms_key.eks.arn
    resources        = ["secrets"]
  }]
  
  # Logging c·ª•m
  cluster_enabled_log_types = [
    "api", "audit", "authenticator", "controllerManager", "scheduler"
  ]
  
  # Nh√≥m node
  eks_managed_node_groups = {
    system = {
      name = "system-nodes"
      
      instance_types = ["t3.medium"]
      capacity_type  = "ON_DEMAND"
      
      min_size     = 2
      max_size     = 4
      desired_size = 2
      
      labels = {
        "node-type" = "system"
      }
      
      taints = [{
        key    = "node-type"
        value  = "system"
        effect = "NO_SCHEDULE"
      }]
    }
    
    application = {
      name = "app-nodes"
      
      instance_types = ["t3.large", "t3.xlarge"]
      capacity_type  = "SPOT"
      
      min_size     = 2
      max_size     = 10
      desired_size = 3
      
      labels = {
        "node-type" = "application"
      }
    }
  }
}
```

## üîê Th·ª±c ti·ªÖn t·ªët nh·∫•t v·ªÅ b·∫£o m·∫≠t

### B·∫£o m·∫≠t m·∫°ng

B·∫£o m·∫≠t m·∫°ng b·∫Øt ƒë·∫ßu v·ªõi vi·ªác c√¥ l·∫≠p subnet ƒë√∫ng c√°ch v√† security group:

```yaml
# terraform/security-groups.tf
resource "aws_security_group" "additional" {
  name_prefix = "${var.cluster_name}-additional"
  vpc_id      = module.vpc.vpc_id
  
  ingress {
    from_port = 22
    to_port   = 22
    protocol  = "tcp"
    cidr_blocks = [module.vpc.vpc_cidr_block]
  }
  
  tags = {
    Name = "${var.cluster_name}-additional"
  }
}
```

### C·∫•u h√¨nh RBAC

Tri·ªÉn khai ki·ªÉm so√°t truy c·∫≠p d·ª±a tr√™n vai tr√≤ ph√π h·ª£p:

```yaml
# k8s/rbac/developer-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: development
  name: developer
rules:
- apiGroups: [""]
  resources: ["pods", "configmaps", "secrets", "services"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
- apiGroups: ["apps"]
  resources: ["deployments", "replicasets"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: developer-binding
  namespace: development
subjects:
- kind: User
  name: developer-team
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: Role
  name: developer
  apiGroup: rbac.authorization.k8s.io
```

## üìä Stack kh·∫£ nƒÉng quan s√°t

### Thi·∫øt l·∫≠p Prometheus v√† Grafana

Tri·ªÉn khai stack gi√°m s√°t to√†n di·ªán:

```yaml
# k8s/monitoring/prometheus-values.yaml
prometheus:
  prometheusSpec:
    retention: 30d
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: gp3
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 50Gi
    
    resources:
      requests:
        memory: 2Gi
        cpu: 1000m
      limits:
        memory: 4Gi
        cpu: 2000m

grafana:
  persistence:
    enabled: true
    storageClassName: gp3
    size: 10Gi
  
  adminPassword: "your-secure-password"
  
  grafana.ini:
    server:
      root_url: "https://grafana.yourdomain.com"
    security:
      disable_gravatar: true
```

### Cluster Autoscaler

Tri·ªÉn khai t·ª± ƒë·ªông m·ªü r·ªông:

```yaml
# k8s/autoscaling/cluster-autoscaler.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cluster-autoscaler
  namespace: kube-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cluster-autoscaler
  template:
    metadata:
      labels:
        app: cluster-autoscaler
    spec:
      serviceAccountName: cluster-autoscaler
      containers:
      - image: k8s.gcr.io/autoscaling/cluster-autoscaler:v1.28.2
        name: cluster-autoscaler
        resources:
          limits:
            cpu: 100m
            memory: 300Mi
          requests:
            cpu: 100m
            memory: 300Mi
        command:
        - ./cluster-autoscaler
        - --v=4
        - --stderrthreshold=info
        - --cloud-provider=aws
        - --skip-nodes-with-local-storage=false
        - --expander=least-waste
        - --node-group-auto-discovery=asg:tag=k8s.io/cluster-autoscaler/enabled,k8s.io/cluster-autoscaler/${CLUSTER_NAME}
        env:
        - name: AWS_REGION
          value: us-west-2
        - name: CLUSTER_NAME
          value: production-eks
```

## üöÄ T·ª± ƒë·ªông h√≥a tri·ªÉn khai

ƒê√¢y l√† script tri·ªÉn khai ho√†n ch·ªânh k·∫øt h·ª£p m·ªçi th·ª© l·∫°i v·ªõi nhau:

```bash
#!/bin/bash
# deploy.sh

set -e

CLUSTER_NAME="production-eks"
AWS_REGION="us-west-2"

echo "üöÄ Tri·ªÉn khai c·ª•m EKS: $CLUSTER_NAME"

# Tri·ªÉn khai h·∫° t·∫ßng v·ªõi Terraform
echo "üì¶ Tri·ªÉn khai h·∫° t·∫ßng..."
cd terraform
terraform init
terraform plan -var="cluster_name=$CLUSTER_NAME"
terraform apply -auto-approve -var="cluster_name=$CLUSTER_NAME"

# C·∫≠p nh·∫≠t kubeconfig
echo "üîß C·∫≠p nh·∫≠t kubeconfig..."
aws eks update-kubeconfig --region $AWS_REGION --name $CLUSTER_NAME

# C√†i ƒë·∫∑t c√°c add-on thi·∫øt y·∫øu
echo "üîå C√†i ƒë·∫∑t c√°c add-on c·ª•m..."

# AWS Load Balancer Controller
helm repo add eks https://aws.github.io/eks-charts
helm repo update
helm install aws-load-balancer-controller eks/aws-load-balancer-controller \
  -n kube-system \
  --set clusterName=$CLUSTER_NAME \
  --set serviceAccount.create=false \
  --set serviceAccount.name=aws-load-balancer-controller

# Prometheus monitoring stack
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm install kube-prometheus-stack prometheus-community/kube-prometheus-stack \
  -n monitoring \
  --create-namespace \
  -f ../k8s/monitoring/prometheus-values.yaml

# Cluster Autoscaler
kubectl apply -f ../k8s/autoscaling/

echo "‚úÖ Tri·ªÉn khai c·ª•m EKS ho√†n t·∫•t!"
echo "üåê Grafana Dashboard: kubectl port-forward -n monitoring svc/kube-prometheus-stack-grafana 3000:80"
echo "üìä Prometheus UI: kubectl port-forward -n monitoring svc/kube-prometheus-stack-prometheus 9090:9090"
```

## üí° M·∫πo s·∫£n xu·∫•t & B√†i h·ªçc kinh nghi·ªám

### 1. T·ªëi ∆∞u h√≥a chi ph√≠

- S·ª≠ d·ª•ng **Spot Instances** cho c√°c workload kh√¥ng quan tr·ªçng (c√≥ th·ªÉ ti·∫øt ki·ªám 60-90%)
- Tri·ªÉn khai **Horizontal Pod Autoscaler** ƒë·ªÉ ƒë·ªãnh k√≠ch th∆∞·ªõc ·ª©ng d·ª•ng ph√π h·ª£p
- **Ki·ªÉm to√°n s·ª≠ d·ª•ng t√†i nguy√™n** th∆∞·ªùng xuy√™n ƒë·ªÉ x√°c ƒë·ªãnh l√£ng ph√≠

### 2. Chi·∫øn l∆∞·ª£c sao l∆∞u

```yaml
# velero-values.yaml
configuration:
  provider: aws
  backupStorageLocation:
    bucket: my-velero-backup-bucket
    config:
      region: us-west-2
  volumeSnapshotLocation:
    config:
      region: us-west-2
schedules:
  daily-backup:
    schedule: "0 2 * * *"
    template:
      ttl: "720h"
      includedNamespaces:
      - production
      - staging
```

### 3. Qu√©t b·∫£o m·∫≠t

Tri·ªÉn khai qu√©t b·∫£o m·∫≠t t·ª± ƒë·ªông:

```yaml
# .github/workflows/security-scan.yml
name: Security Scan
on:
  push:
    branches: [main]
jobs:
  security-scan:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'
```

## üéâ K·∫øt lu·∫≠n

X√¢y d·ª±ng c√°c c·ª•m EKS s·∫µn s√†ng cho s·∫£n xu·∫•t ƒë√≤i h·ªèi l·∫≠p k·∫ø ho·∫°ch c·∫©n th·∫≠n v√† ch√∫ √Ω ƒë·∫øn chi ti·∫øt. C·∫•u h√¨nh m√† t√¥i ƒë√£ chia s·∫ª ·ªü ƒë√¢y t·∫°o n√™n m·ªôt n·ªÅn t·∫£ng v·ªØng ch·∫Øc, nh∆∞ng h√£y nh·ªõ r·∫±ng m·ªói m√¥i tr∆∞·ªùng s·∫£n xu·∫•t ƒë·ªÅu c√≥ nh·ªØng y√™u c·∫ßu ri√™ng bi·ªát.

Nh·ªØng ƒëi·ªÉm ch√≠nh c·∫ßn nh·ªõ:
- **B·∫Øt ƒë·∫ßu v·ªõi n·ªÅn t·∫£ng VPC v·ªØng ch·∫Øc**
- **Tri·ªÉn khai b·∫£o m·∫≠t t·ª´ ng√†y ƒë·∫ßu**
- **L·∫≠p k·∫ø ho·∫°ch cho kh·∫£ nƒÉng quan s√°t v√† gi√°m s√°t**
- **T·ª± ƒë·ªông h√≥a m·ªçi th·ª© c√≥ th·ªÉ**
- **Ki·ªÉm tra c√°c quy tr√¨nh kh√¥i ph·ª•c th·∫£m h·ªça c·ªßa b·∫°n**

Trong b√†i vi·∫øt ti·∫øp theo, t√¥i s·∫Ω ƒëi s√¢u h∆°n v√†o **c√°c m·∫´u m·∫°ng EKS n√¢ng cao** v√† **t√≠ch h·ª£p service mesh**. H√£y theo d√µi!

---

*C√≥ c√¢u h·ªèi v·ªÅ EKS ho·∫∑c mu·ªën chia s·∫ª tr·∫£i nghi·ªám c·ªßa ri√™ng b·∫°n? H√£y li√™n h·ªá v·ªõi t√¥i tr√™n [LinkedIn](https://www.linkedin.com/in/alexpham15010305) ho·∫∑c g·ª≠i [email](mailto:phamtunglam.workmail.public@gmail.com).*
